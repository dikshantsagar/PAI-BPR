{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PAIBPR-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjaBSlmrTe2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import *\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "from torch.nn.functional import logsigmoid\n",
        "from torch import load, sigmoid, cat, rand, bmm, mean, matmul\n",
        "from torch.optim import Adam\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsPCtBcttD9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCYhz5ETTqCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = {\n",
        "    'visfeat' : '/content/drive/My Drive/Group_9/src/data/train/feat/visualfeatures',\n",
        "    'textfeat': '/content/drive/My Drive/Group_9/src/data/train/feat/textfeatures',\n",
        "    'textembedmat' : '/content/drive/My Drive/Group_9/src/data/train/feat/smallnwjc2vec',\n",
        "    'traindata' : '/content/drive/My Drive/Group_9/src/data/train/data/train.csv',\n",
        "    'testdata' : '/content/drive/My Drive/Group_9/src/data/train/data/test.csv',\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_9Cc0ftUlJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BPR(Module):\n",
        "\n",
        "  def __init__(self, userset:iter, itemset:iter, hidden_dim = 512):\n",
        "    super(BPR, self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.user_alpha = Embedding(len(userset), self.hidden_dim)\n",
        "    self.item_alpha = Embedding(len(itemset), self.hidden_dim)\n",
        "    self.user_beta = Embedding(len(userset), 1)\n",
        "    self.item_beta = Embedding(len(itemset), 1)\n",
        "\n",
        "    init.uniform_(self.user_alpha.weight, 0, 0.01)\n",
        "    init.uniform_(self.user_beta.weight, 0, 0.01)\n",
        "    init.uniform_(self.item_alpha.weight, 0, 0.01)\n",
        "    init.uniform_(self.item_beta.weight, 0, 0.01)\n",
        "\n",
        "    self.user_set = list(userset)\n",
        "    self.item_set = list(itemset)\n",
        "\n",
        "    self.user_idx = {user : ind for ind, user in enumerate(userset)}\n",
        "    self.item_idx = {item : ind for ind , item in enumerate(itemset)}\n",
        "\n",
        "  def get_user_idx(self, users):\n",
        "    return torch.tensor([self.user_idx[user] for user in users]).long().to(device)\n",
        "\n",
        "  def get_item_idx(self, items):\n",
        "    return torch.tensor([self.item_idx[item] for item in items]).long().to(device)\n",
        "  \n",
        "\n",
        "  def forward(self, users, items):\n",
        "\n",
        "    batchsize = len(users)\n",
        "    user_alpha = self.user_alpha(self.get_user_idx(users))\n",
        "    user_beta = self.user_beta(self.get_user_idx(users))\n",
        "    item_alpha = self.item_alpha(self.get_item_idx(items))\n",
        "    item_beta = self.item_beta(self.get_item_idx(items))\n",
        "\n",
        "    out = user_beta.view(batchsize) + item_beta.view(batchsize) \\\n",
        "          + bmm(user_alpha.view(batchsize,1,self.hidden_dim),\n",
        "                item_alpha.view(batchsize,self.hidden_dim,1)).view(batchsize)\n",
        "\n",
        "    return out\n",
        "  \n",
        "  def fit(self, users, items):\n",
        "\n",
        "    batchsize = len(users)\n",
        "    user_alpha = self.user_alpha(self.get_user_idx(users))\n",
        "    user_beta = self.user_beta(self.get_user_idx(users))\n",
        "    item_alpha = self.item_alpha(self.get_item_idx(items))\n",
        "    item_beta = self.item_beta(self.get_item_idx(items))\n",
        "\n",
        "    out = user_beta.view(batchsize) + item_beta.view(batchsize) \\\n",
        "          + bmm(user_alpha.view(batchsize,1,self.hidden_dim),\n",
        "                item_alpha.view(batchsize,self.hidden_dim,1)).view(batchsize)\n",
        "\n",
        "    outweight = user_alpha.norm(p=2) + user_beta.norm(p=2) + item_alpha.norm(p=2) + item_beta.norm(p=2)\n",
        "\n",
        "    return out, outweight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc2F6l9oURQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VTBPR(BPR):\n",
        "\n",
        "  def __init__(self, userset, itemset, hidden_dim=512):\n",
        "    super(VTBPR, self).__init__(userset, itemset, hidden_dim=hidden_dim)\n",
        "\n",
        "    self.user_visembed = Embedding(len(userset), self.hidden_dim)\n",
        "    self.user_textembed = Embedding(len(userset), self.hidden_dim)\n",
        "\n",
        "    init.uniform_(self.user_visembed.weight, 0, 0.01)\n",
        "    init.uniform_(self.user_textembed.weight, 0, 0.01)\n",
        "\n",
        "  def forward(self, users, items, visfeat, textfeat):\n",
        "    batchsize = len(users)\n",
        "    bpr = BPR.forward(self, users, items)\n",
        "    theta_user_vis = self.user_visembed(self.get_user_idx(users))\n",
        "    theta_user_text = self.user_textembed(self.get_user_idx(users))\n",
        "\n",
        "    out1 = bmm(theta_user_vis.view(batchsize,1,self.hidden_dim),\n",
        "               visfeat.view(batchsize,self.hidden_dim,1)).view(batchsize)\n",
        "    out2 = bmm(theta_user_text.view(batchsize,1,self.hidden_dim),\n",
        "               textfeat.view(batchsize,self.hidden_dim,1)).view(batchsize)\n",
        "\n",
        "    return bpr + out1 + out2\n",
        "  \n",
        "  def fit(self, users, items, visfeat, textfeat):\n",
        "    batchsize = len(users)\n",
        "    bpr, bprweight = BPR.fit(self, users, items)\n",
        "    theta_user_vis = self.user_visembed(self.get_user_idx(users))\n",
        "    theta_user_text = self.user_textembed(self.get_user_idx(users))\n",
        "\n",
        "    out1 = bmm(theta_user_vis.view(batchsize,1,self.hidden_dim),\n",
        "               visfeat.view(batchsize,self.hidden_dim,1)).view(batchsize)\n",
        "    out2 = bmm(theta_user_text.view(batchsize,1,self.hidden_dim),\n",
        "               textfeat.view(batchsize,self.hidden_dim,1)).view(batchsize)\n",
        "    \n",
        "    outweight = bprweight + self.user_visembed(self.get_user_idx(set(users))).norm(p=2) \\\n",
        "                          + self.user_textembed(self.get_user_idx(set(users))).norm(p=2)\n",
        "\n",
        "    return bpr + out1 + out2 , outweight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBQwPnIqes7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextCNN(Module):\n",
        "  def __init__(self, sent_size = (83,300), output_size = 512):\n",
        "    super(TextCNN,self).__init__()\n",
        "    self.max_length , self.wordvec_size = sent_size\n",
        "\n",
        "    self.textcnn = ModuleList([Sequential(\n",
        "        Conv2d(in_channels=1,out_channels=100,kernel_size=(2,self.wordvec_size),stride=1),\n",
        "        Sigmoid(),\n",
        "        MaxPool2d(kernel_size=(self.max_length-1,1),stride=1)),\n",
        "        Sequential(\n",
        "        Conv2d(in_channels=1,out_channels=100,kernel_size=(3,self.wordvec_size),stride=1),\n",
        "        Sigmoid(),\n",
        "        MaxPool2d(kernel_size=(self.max_length-2,1),stride=1)),\n",
        "        Sequential(\n",
        "        Conv2d(in_channels=1,out_channels=100,kernel_size=(4,self.wordvec_size),stride=1),\n",
        "        Sigmoid(),\n",
        "        MaxPool2d(kernel_size=(self.max_length-3,1),stride=1)),\n",
        "        Sequential(\n",
        "        Conv2d(in_channels=1,out_channels=100,kernel_size=(5,self.wordvec_size),stride=1),\n",
        "        Sigmoid(),\n",
        "        MaxPool2d(kernel_size=(self.max_length-4,1),stride=1))\n",
        "        ])\n",
        "    \n",
        "    self.textnn = Sequential(\n",
        "        Linear(in_features=400,out_features=output_size),\n",
        "        Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "\n",
        "    conv = cat([conv2d(input).squeeze_(-1).squeeze_(-1) for conv2d in self.textcnn], 1)\n",
        "    output = self.textnn(conv)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6t3lqtCjTMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PAIBPR(Module):\n",
        "\n",
        "  def __init__(self, userset, itemset, embedding_weight, maxsentlen = 83, textfeat_dim = 300, visfeat_dim = 2048, hidden_dim = 512, uniform = 0.5):\n",
        "    super(PAIBPR, self).__init__()\n",
        "\n",
        "    self.uniform = uniform\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.maxsentlen = maxsentlen\n",
        "    self.epoch = 0\n",
        "\n",
        "    self.visencoder = Sequential(\n",
        "        Linear(in_features=visfeat_dim,out_features=hidden_dim),\n",
        "        Sigmoid()\n",
        "    )\n",
        "\n",
        "    self.visencoder[0].apply(lambda module: init.uniform_(module.weight.data,0,0.001))\n",
        "    self.visencoder[0].apply(lambda module: init.uniform_(module.bias.data,0,0.001))\n",
        "\n",
        "    self.text_embedding = Embedding.from_pretrained(embedding_weight, freeze=False)\n",
        "\n",
        "    self.vtbpr = VTBPR(userset=userset, itemset=itemset, hidden_dim= self.hidden_dim)\n",
        "    self.textcnn = TextCNN(sent_size=(self.maxsentlen,textfeat_dim), output_size=self.hidden_dim)\n",
        "\n",
        "  def forward(self, batch, visfeat, textfeat):\n",
        "\n",
        "    Us = [str(int(pair[0])) for pair in batch]\n",
        "    Is = [str(int(pair[1])) for pair in batch]\n",
        "    Js = [str(int(pair[2])) for pair in batch]\n",
        "    Ks = [str(int(pair[3])) for pair in batch]\n",
        "\n",
        "    with torch.cuda.device(torch.cuda.current_device()):\n",
        "      stream1 = torch.cuda.Stream()\n",
        "      stream2 = torch.cuda.Stream()\n",
        "\n",
        "      Ivis = self.visencoder(cat([visfeat[I].unsqueeze(0) for I in Is], 0).to(device))\n",
        "      with torch.cuda.stream(stream1):\n",
        "        Jvis = self.visencoder(cat([visfeat[J].unsqueeze(0) for J in Js], 0).to(device))\n",
        "      with torch.cuda.stream(stream2):\n",
        "        Kvis = self.visencoder(cat([visfeat[K].unsqueeze(0) for K in Ks], 0).to(device))\n",
        "\n",
        "      Itext = self.textcnn(self.text_embedding(cat([textfeat[I].unsqueeze(0) for I in Is], 0).to(device)).unsqueeze_(1))\n",
        "      with torch.cuda.stream(stream1):\n",
        "        Jtext = self.textcnn(self.text_embedding(cat([textfeat[J].unsqueeze(0) for J in Js], 0).to(device)).unsqueeze_(1))\n",
        "      with torch.cuda.stream(stream2):\n",
        "        Ktext = self.textcnn(self.text_embedding(cat([textfeat[K].unsqueeze(0) for K in Ks], 0).to(device)).unsqueeze_(1))\n",
        "      \n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    stream1 = torch.cuda.Stream()\n",
        "    stream2 = torch.cuda.Stream()\n",
        "\n",
        "    vis_ij = bmm(Ivis.unsqueeze(1), Jvis.unsqueeze(-1)).squeeze_(-1).squeeze_(-1)\n",
        "    with torch.cuda.stream(stream1):\n",
        "      text_ij = bmm(Itext.unsqueeze(1), Jtext.unsqueeze(-1)).squeeze_(-1).squeeze_(-1)\n",
        "      cuj = self.vtbpr(Us, Js, Jvis, Jtext)\n",
        "    \n",
        "    vis_ik = bmm(Ivis.unsqueeze(1), Kvis.unsqueeze(-1)).squeeze_(-1).squeeze_(-1)\n",
        "    with torch.cuda.stream(stream2):\n",
        "      text_ik = bmm(Itext.unsqueeze(1), Ktext.unsqueeze(-1)).squeeze_(-1).squeeze_(-1)\n",
        "      cuk = self.vtbpr(Us, Ks, Kvis, Ktext)\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    p_ij = 0.5 * vis_ij + 0.5 * text_ij\n",
        "    p_ik = 0.5 * vis_ik + 0.5 * text_ik\n",
        "\n",
        "    return self.uniform * p_ij + (1 - self.uniform) * cuj - ( self.uniform * p_ik + (1 - self.uniform) * cuk )\n",
        "\n",
        "\n",
        "  def fit(self, batch, visfeat, textfeat):\n",
        "\n",
        "    Us = [str(int(pair[0])) for pair in batch]\n",
        "    Is = [str(int(pair[1])) for pair in batch]\n",
        "    Js = [str(int(pair[2])) for pair in batch]\n",
        "    Ks = [str(int(pair[3])) for pair in batch]\n",
        "\n",
        "    with torch.cuda.device(torch.cuda.current_device()):\n",
        "      stream1 = torch.cuda.Stream()\n",
        "      stream2 = torch.cuda.Stream()\n",
        "\n",
        "      Ivis = self.visencoder(cat([visfeat[I].unsqueeze(0) for I in Is], 0).to(device))\n",
        "      with torch.cuda.stream(stream1):\n",
        "        Jvis = self.visencoder(cat([visfeat[J].unsqueeze(0) for J in Js], 0).to(device))\n",
        "      with torch.cuda.stream(stream2):\n",
        "        Kvis = self.visencoder(cat([visfeat[K].unsqueeze(0) for K in Ks], 0).to(device))\n",
        "\n",
        "      Itext = self.textcnn(self.text_embedding(cat([textfeat[I].unsqueeze(0) for I in Is], 0).to(device)).unsqueeze_(1))\n",
        "      with torch.cuda.stream(stream1):\n",
        "        Jtext = self.textcnn(self.text_embedding(cat([textfeat[J].unsqueeze(0) for J in Js], 0).to(device)).unsqueeze_(1))\n",
        "      with torch.cuda.stream(stream2):\n",
        "        Ktext = self.textcnn(self.text_embedding(cat([textfeat[K].unsqueeze(0) for K in Ks], 0).to(device)).unsqueeze_(1))\n",
        "      \n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    stream1 = torch.cuda.Stream()\n",
        "    stream2 = torch.cuda.Stream()\n",
        "\n",
        "    vis_ij = bmm(Ivis.unsqueeze(1), Jvis.unsqueeze(-1)).squeeze_(-1).squeeze_(-1)\n",
        "    with torch.cuda.stream(stream1):\n",
        "      text_ij = bmm(Itext.unsqueeze(1), Jtext.unsqueeze(-1)).squeeze_(-1).squeeze_(-1)\n",
        "      cuj, cujweight = self.vtbpr.fit(Us, Js, Jvis, Jtext)\n",
        "    \n",
        "    vis_ik = bmm(Ivis.unsqueeze(1), Kvis.unsqueeze(-1)).squeeze_(-1).squeeze_(-1)\n",
        "    with torch.cuda.stream(stream2):\n",
        "      text_ik = bmm(Itext.unsqueeze(1), Ktext.unsqueeze(-1)).squeeze_(-1).squeeze_(-1)\n",
        "      cuk, cukweight = self.vtbpr.fit(Us, Ks, Kvis, Ktext)\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    p_ij = 0.5 * vis_ij + 0.5 * text_ij\n",
        "    p_ik = 0.5 * vis_ik + 0.5 * text_ik\n",
        "\n",
        "    output = self.uniform * p_ij + (1 - self.uniform) * cuj - ( self.uniform * p_ik + (1 - self.uniform) * cuk )\n",
        "\n",
        "    cujkweight = self.vtbpr.user_alpha(self.vtbpr.get_user_idx(set(Us))).norm(p=2) + self.vtbpr.item_alpha(self.vtbpr.get_item_idx(set(Js+Ks))).norm(p=2) \\\n",
        "              + self.vtbpr.user_visembed(self.vtbpr.get_user_idx(set(Us))).norm(p=2) + self.vtbpr.user_textembed(self.vtbpr.get_user_idx(set(Us))).norm(p=2)\n",
        "    \n",
        "    outweight = cujkweight + self.text_embedding(cat([textfeat[I].unsqueeze(0) for I in set(Is+Js+Ks)], 0).cuda()).norm(p=2)\n",
        "\n",
        "    return  output, outweight\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozyeOpSiu1sH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_csv_data(train_data_path):\n",
        "    result = []\n",
        "    with open(train_data_path,'r') as fp:\n",
        "        for line in fp:\n",
        "            t = line.strip().split(',')\n",
        "            t = [int(i) for i in t]\n",
        "            result.append(t)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21jm1-6xvZIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_embedding_weight(device):\n",
        "    jap2vec = torch.load(config['textembedmat'])\n",
        "    embeding_weight = []\n",
        "    for jap, vec in jap2vec.items():\n",
        "        embeding_weight.append(vec.tolist())\n",
        "    embeding_weight.append(torch.zeros(300))\n",
        "    embedding_weight = torch.tensor(embeding_weight, device=device)\n",
        "    return embedding_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7Ck-5TKvfgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, traindata, visfeat, textfeat, optim):\n",
        "\n",
        "  model.train()\n",
        "  trainloss = 0\n",
        "  for i, batch in enumerate(traindata):\n",
        "    output, outputweight = model.fit(batch[0], visfeat, textfeat)\n",
        "    loss = (-logsigmoid(output)).sum() + 0.001*outputweight\n",
        "    trainloss += loss\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "  print('Training Loss : ', trainloss.item()/len(traindata))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAjq-mkHxRrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, test_csv, visfeat, textfeat):\n",
        "\n",
        "  model.eval()\n",
        "  testdata = load_csv_data(test_csv)\n",
        "  pos = 0\n",
        "  batchs = 100\n",
        "  for i in range(0, len(testdata), batchs):\n",
        "    data = testdata[i:i+batchs] if i+batchs <=len(testdata) else testdata[i:]\n",
        "    output = model.forward(data, visfeat, textfeat)  \n",
        "    pos += float(torch.sum(output.ge(0)))\n",
        "  auc = pos/len(testdata)\n",
        "  print( \"Testing....    Epoch : \", model.epoch,' AUC: ', auc )\n",
        "  return auc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC50zn-4yCpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hiUyse3D91x",
        "colab_type": "code",
        "outputId": "46ae51fd-2af3-4c3d-b9f4-5933f8093113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hidden_dim=512\n",
        "batch_size=256\n",
        "uniform = 0.05\n",
        "epochs=60\n",
        "print('loading top&bottom features')\n",
        "train_data = load_csv_data(config['traindata'])\n",
        "visfeat = torch.load(config['visfeat'],map_location= lambda storage, loc: storage.cuda())\n",
        "textfeat = torch.load(config['textfeat'],map_location=lambda storage, loc: storage.cuda())\n",
        "\n",
        "\n",
        "embedding_weight = load_embedding_weight(torch.cuda.current_device())\n",
        "item_set= set()\n",
        "user_set = set([str(i[0]) for i in train_data])\n",
        "for i in train_data:\n",
        "  item_set.add(str(int(i[2])))\n",
        "  item_set.add(str(int(i[3])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading top&bottom features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBHb5qxEGBd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = PAIBPR(userset = user_set, itemset = item_set, embedding_weight=embedding_weight, uniform = uniform).to(torch.cuda.current_device())\n",
        "\n",
        "optim = Adam([\n",
        "    {\n",
        "        'params' : model.parameters(),\n",
        "        'lr' : 0.001,\n",
        "        'weight_decay' : 0.00012  #0.0002 #\n",
        "    }\n",
        "    ])\n",
        "  \n",
        "train_data = TensorDataset(torch.tensor(train_data, dtype=torch.int))\n",
        "train_loader = DataLoader(train_data, batch_size= batch_size,shuffle=True, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96EbJGVWEMNc",
        "colab_type": "code",
        "outputId": "00daf3ea-2240-4a96-820a-a99146630611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "aucs = []     # for plot\n",
        "for i in range(epochs): \n",
        "  train(model, train_loader, visfeat, textfeat, optim)\n",
        "  model.epoch+=1\n",
        "  testauc = evaluate(model, config['testdata'], visfeat, textfeat)\n",
        "  aucs.append(testauc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss :  161.5860408399471\n",
            "Testing....    Epoch :  1  AUC:  0.6941329292054558\n",
            "Training Loss :  96.83493510251323\n",
            "Testing....    Epoch :  2  AUC:  0.7656202641264342\n",
            "Training Loss :  34.05472366898148\n",
            "Testing....    Epoch :  3  AUC:  0.7857111928988959\n",
            "Training Loss :  9.99207447193287\n",
            "Testing....    Epoch :  4  AUC:  0.7935483870967742\n",
            "Training Loss :  4.886344142691799\n",
            "Testing....    Epoch :  5  AUC:  0.7992639099372159\n",
            "Training Loss :  3.4934443721064814\n",
            "Testing....    Epoch :  6  AUC:  0.8004329941545789\n",
            "Training Loss :  2.942885948867394\n",
            "Testing....    Epoch :  7  AUC:  0.8050660316085733\n",
            "Training Loss :  2.6901978184937168\n",
            "Testing....    Epoch :  8  AUC:  0.8076639965360468\n",
            "Training Loss :  2.5802964306382274\n",
            "Testing....    Epoch :  9  AUC:  0.811560943927257\n",
            "Training Loss :  2.7393240146536044\n",
            "Testing....    Epoch :  10  AUC:  0.8155011907339251\n",
            "Training Loss :  2.552433558872768\n",
            "Testing....    Epoch :  11  AUC:  0.8123836328209569\n",
            "Training Loss :  2.5702232078269676\n",
            "Testing....    Epoch :  12  AUC:  0.8213899112361983\n",
            "Training Loss :  2.4406859382750494\n",
            "Testing....    Epoch :  13  AUC:  0.8243775709027928\n",
            "Training Loss :  2.456638073795056\n",
            "Testing....    Epoch :  14  AUC:  0.8198311322797143\n",
            "Training Loss :  2.4833307821283896\n",
            "Testing....    Epoch :  15  AUC:  0.8295302013422818\n",
            "Training Loss :  2.4869602748325894\n",
            "Testing....    Epoch :  16  AUC:  0.8303095908205239\n",
            "Training Loss :  2.5757296123201887\n",
            "Testing....    Epoch :  17  AUC:  0.8316085732842606\n",
            "Training Loss :  2.5135864580749834\n",
            "Testing....    Epoch :  18  AUC:  0.8316951721151764\n",
            "Training Loss :  2.5601130086908896\n",
            "Testing....    Epoch :  19  AUC:  0.8341199393808184\n",
            "Training Loss :  2.611191199570106\n",
            "Testing....    Epoch :  20  AUC:  0.8311755791296818\n",
            "Training Loss :  2.686838624338624\n",
            "Testing....    Epoch :  21  AUC:  0.8350725265208919\n",
            "Training Loss :  2.648379371279762\n",
            "Testing....    Epoch :  22  AUC:  0.8281013206321715\n",
            "Training Loss :  2.692243626508763\n",
            "Testing....    Epoch :  23  AUC:  0.8357653171682182\n",
            "Training Loss :  2.726053227823247\n",
            "Testing....    Epoch :  24  AUC:  0.8299198960814029\n",
            "Training Loss :  2.7872001203910384\n",
            "Testing....    Epoch :  25  AUC:  0.8353323230136394\n",
            "Training Loss :  2.763888888888889\n",
            "Testing....    Epoch :  26  AUC:  0.8352457241827236\n",
            "Training Loss :  2.803098648313492\n",
            "Testing....    Epoch :  27  AUC:  0.8321714656852133\n",
            "Training Loss :  2.8374685459036044\n",
            "Testing....    Epoch :  28  AUC:  0.8352890235981815\n",
            "Training Loss :  2.893850498098545\n",
            "Testing....    Epoch :  29  AUC:  0.83347044814895\n",
            "Training Loss :  2.92337730448082\n",
            "Testing....    Epoch :  30  AUC:  0.8328642563325395\n",
            "Training Loss :  2.9306711671213623\n",
            "Testing....    Epoch :  31  AUC:  0.8322147651006712\n",
            "Training Loss :  2.997955806671627\n",
            "Testing....    Epoch :  32  AUC:  0.8311322797142239\n",
            "Training Loss :  2.996455439814815\n",
            "Testing....    Epoch :  33  AUC:  0.8320415674388396\n",
            "Training Loss :  3.0264724650710977\n",
            "Testing....    Epoch :  34  AUC:  0.8257631521974453\n",
            "Training Loss :  3.0724574497767856\n",
            "Testing....    Epoch :  35  AUC:  0.830655986144187\n",
            "Training Loss :  3.103166529741237\n",
            "Testing....    Epoch :  36  AUC:  0.8268889369993505\n",
            "Training Loss :  3.0953814794146823\n",
            "Testing....    Epoch :  37  AUC:  0.827884823554882\n",
            "Training Loss :  3.1339770120287698\n",
            "Testing....    Epoch :  38  AUC:  0.8276683264775926\n",
            "Training Loss :  3.1970999581473216\n",
            "Testing....    Epoch :  39  AUC:  0.8266291405066032\n",
            "Training Loss :  3.2104676261780756\n",
            "Testing....    Epoch :  40  AUC:  0.8221260012989825\n",
            "Training Loss :  3.211176150690311\n",
            "Testing....    Epoch :  41  AUC:  0.8232084866854298\n",
            "Training Loss :  3.237644740513393\n",
            "Testing....    Epoch :  42  AUC:  0.8189218445550985\n",
            "Training Loss :  3.300063683242394\n",
            "Testing....    Epoch :  43  AUC:  0.823121887854514\n",
            "Training Loss :  3.3099381381241733\n",
            "Testing....    Epoch :  44  AUC:  0.8181424550768565\n",
            "Training Loss :  3.318493393993882\n",
            "Testing....    Epoch :  45  AUC:  0.820697120588872\n",
            "Training Loss :  3.3622817589492393\n",
            "Testing....    Epoch :  46  AUC:  0.817925957999567\n",
            "Training Loss :  3.3668690837880293\n",
            "Testing....    Epoch :  47  AUC:  0.8188785451396406\n",
            "Training Loss :  3.4190996765459656\n",
            "Testing....    Epoch :  48  AUC:  0.8200909287724616\n",
            "Training Loss :  3.432059474723049\n",
            "Testing....    Epoch :  49  AUC:  0.8206105217579562\n",
            "Training Loss :  3.4426492358010914\n",
            "Testing....    Epoch :  50  AUC:  0.8157609872266725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8a40f24721b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maucs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m     \u001b[0;31m# for plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtestauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'testdata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e987dce37013>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, traindata, visfeat, textfeat, optim)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrainloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Loss : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUrRx2iB3eVn",
        "colab_type": "code",
        "outputId": "1f59cb13-bda0-44a3-b748-f1035d1e5de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('TestSet Accuracy')\n",
        "plt.plot(aucs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0874549278>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEJCAYAAABlmAtYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deVzUdf7A8ddnGBUFUWZGwQMzULQ8MsJC8obaXStz3bS7TLfd0rLV7ZDSzVZZKbVszWuNlbJto7vtsPyRqQVZlrd54ZUHyjGKCCLH9/P7Y3RyBGRChwHm/Xw8esB3vp/vfN8fpHnz/ZxKa60RQgghLsDk7QCEEELUfZIshBBCVEuShRBCiGpJshBCCFEtSRZCCCGqJclCCCFEtcy1daMNGzawZMkSDMMgLi6OYcOGuZzPzc1l3rx5FBYWYhgGd911F1FRUS7nJ0yYwIgRIxg6dGi19zt8+HCNY7XZbOTm5tb4+vpK6u1bpN6+xZ16t23btspztZIsDMMgOTmZyZMnY7VaSUhIIDo6mvbt2zvLvPfee/Tp04cbb7yRgwcPMmPGDJdk8dprr3H11VfXRrhCCCHOUyvNUJmZmYSGhhISEoLZbCY2Npa1a9e6lFFKUVRUBEBRURHBwcHOc99//z2tW7d2SS5CCCFqT608WdjtdqxWq/PYarWya9culzIjRoxg+vTpfP7555w+fZopU6YAUFxczEcffcSUKVP43//+V+U90tLSSEtLAyApKQmbzVbjeM1m80VdX19JvX2L1Nu3XGy9a63Pojrp6ekMHDiQW265hZ07dzJ37lxmz57N22+/zU033YS/v/8Fr4+Pjyc+Pt55fDFtktKm6Vuk3r5F6l01r/dZWCwW8vLynMd5eXlYLBaXMitWrODpp58GIDIyktLSUgoKCsjMzOS7777jP//5D4WFhSilaNy4Mb/97W9rI3QhhBDUUrKIiIggKyuL7OxsLBYLGRkZjB8/3qWMzWZjy5YtDBw4kIMHD1JaWkpQUBB///vfnWXefvtt/P39JVEIIUQtq5Vk4efnx+jRo0lMTMQwDAYNGkRYWBipqalEREQQHR3Nfffdx6JFi/j0008BGDt2LEqp2ghPCCFENVRDXaJc5ln8elLv6ukTx9E/rUddOwBlqt9zWuXf27fUiz4LIeoirTX6h28o7dQFglu7dY3x2lzYtBbyj6F+M7z6exScwJj/D8g9Cn5+4Gd2+aq69EANvQvVpEn1sX69HP39alTP3qjYwajAILdiFuJSkGQhGgytNeQcgVah1TZhaqMc/fa/0V9+zPGWFpj6Ciog8MLXbPnRkShaWtHvv46+vAsqslvV5cvKMBYmwb5dqGv7g2FAeRm6vBzKy+B0MXr5B+hN32MaPRF1eefK3+fEcYzXX4GN3zvu/c6/0R8sRfXuixrwOwjvIk22wuMkWYgGQe/cgvFuCuzdCb1iMN3zMKpFcOVlT5/GeHU2bFiDunYAxg/foN5dgrr/0arfv6wMI/VVaN0G06SZGElPYiyeiWnKHFRQy8qveetfsHMLaswETDGDKi/z0waMlH9iJD2Buul21JARKPMv/1vqjWsxXvsnnCpC3T4GNfgWOLwfvepz9Lcr0d9+Be0vRw34DSq8C7Rqg2razP0fnBBu8ps6depUbwfhCQUFBTW+tlmzZs7Z5L6kPtZbH/4Z47W56PdfB0DFxsHar9Grv4CWFmjf0eWvbl2QjzHnWdixCXX7HzGNeICmforS5R+iIruhbCGV3+fLj+G7VZgemIDqEI7q0g294lP0vl2o6waglGv/hbHyM/THb6F+MxzTjb+vMn7VKhR1fRwcy0Wv+AS9dZ3jaaVRY/R//4V+59+OBPWX5zD1ug6lFCoo2NEUNfgmsLaGfZmQnoZe/QV62bvorz5Fr8uA7ZvRB/ei7blQchoaN0Y1/qW5qz7+e18KUu+qNW/evMpz0sFdCekAq/v08Tz0//6L/iYN/P1Rv7sNFXcLqnETdNZBx1/ju7dDz96Y7hmLCraijx7GeHkqHLdj+uNfUVF9ALA2DyT70btAKUzP/tPlAxXONANNfgjCu2B6bKoz+Rjf/B/6tbmom+/AdOtdv5Tfvgnjpb9BtyhMjzyDMvm5V6cf0zGWzofS0xAUDHnZqBuHoW69B9WoUdXXaQ2Hf4YjB9HZRyAnC51zxNEkZ88FbfxSuFkghLRFhbQlILIbRe06QocIl6eZSt8/5wgct0PnK+t9k1d9+j2/lKSDWzQ4uuQ07NiC3vwDOicLzrbxl5dD2Zmv2Yeg3HAkiJtGuHT2qjbtMT05A/3lJ+gPl2I8+wjqxlsdTwcoTH+djoro+kv5Jv6Y7h2H8eIU9CepqOH3ucbz4RtQchrT7Q+6fFCa+t6Asesn9Kep6E5XoLpdjc45grHweQhph+nBx91OFADqmusxRVyB8cZ8OLTfEWeXHtVfpxS0uwzaXcb5H+O6rNTRuX40C330EGQfRh89jN6xhZNrVjoKNfGHiK6ozt0cTzXBNjiwB70vE70/0/HkUnTSca97x6L6yzwnXyTJQtQJOi/bkRw2/QA7NkFJCTRuAm07gNkMJj/HcdMAxyiiTl1RN/4e1Sq00vdTJj/UDbeir+qNkfJP9EdvOppzHnsW1briX0/qiqtQsXHoL95H9+6HCrvcEdf+3ehv/g8VNxTVpuJCluquh9D7MzFenY3pyRmORKG144miBn0HqqUFv0cmo7W+JH/BK3MjCG0Poe1R9HY5F+ynsH/3NXrnVvSureiP/oNLM4OfnyMBXRMLHTujv1+NTk1GR/ZAhbar9t563y4IaomytLroegjvk2aoSshjqudooxyyj8Ch/egz/3FwL2RnOQq0CkX1iEb1iIYu3VGNGl+Cexqw+UeI6FLpcNOz9dYnT2D8bRxYW2NKeAGUCeOFSXD0MKbpC1DNKh8tpY8cxJj+VygvBcPA9JfnUFdcddFxe9r5/966sAB2/YQ+bkd1CIewy11+/vpYHsZz48EWgmnS845EVAW9aS3GvERoGoDp4QRUl+4ercuvIf9/V02aoYTX6VNFjr+6M7c6nhoAlIJWoY6/Xgf8FtWjN4S2u+Rt4spkgqt6V18uMAh1x4PoxbPQKz5x9BtkbkPdO67KRAGgQtuj7n8U/eos1O1/rBeJojIqoDn0uq5CU5bzfLAV033jMBYkof/33wrNdWfpzG0Yi56H9h2hpATjpb+h7h2H6fo4j8UuPE+ShagVevUX8NN61KAhcFknVLvLoE2Haiej1TbVux96zUr0B29AswDoEI7qG1/tdabefdE9olD+DXvYqoqKRfW9Af35e+juUahI1ycGfehnjLnToKUN02NTwWzGWPg8OuVljKMHUcPurfcz332VJAvhcbqsFJ32P+jSA9NdD3k7nAtSSmG6+2GMZx9xjJr605Nud1I39ERxlrr9j455LckvOkaPnXnq0nk5jmHJjRph+stU5/wT0/hnHcOAl72HPnrYMQHxnD8StNaQexS9e7tj1FXjJuDfFJr4o858JSDQ8cfFBUaFCc+SZCE8Tn+/Go7nYbr/EW+H4hZlbYXpT4+js7NQna/0djh1jvJviumPf8VIehL9xgJ48HE4WeBIFKdPYXpyhsvAA2U2wz0PQ2g79Dv/xpiZgOn39zrmgGRuhz3b4cTxSu/l0qFqbgQdO6M6X4HqdCVEXFHtrHtx6UiyEB6ltUZ/8YFjaGe3qOovqCNUz95Vtt0LUJdHom65E/3Rf6BLD3R6GuQexTThOVT7yyuWV8oxOq11G4zFsxyJBaB1G9SVVzsGH0RcAW3CoKwEiouh+BScPvP1ZD56zw70rp/Qyz9EL3vPcX27yzD9YRSqxzW1WHvfJMlCeNaWH+Hwz6jRE+r9ZC7hSg25Db11PfqN+aBMmB6eVKEPo8I1V12L6dl/QtYBuDwS1bxFxUJmM1TSpKeuuR5wLNfCvp3ozG3o71ZhzE/ENPZpxwg64THS0yQ8yvjiAwi2oXr383Yo4hJTJj9MYyY4RrPd/wjq6hj3rmsV6nhyqyxRuHN9kyaoLj0w3TQS01PPQ9vLMObPQG9ZV6P3E+6RZCFqRG/+EeOL9x1zGKoqs3cX7NiMih96weUkRP2lbCH4TZ2L6frqR4x55P4BgZgm/h3atMeYl4j+ab1X4vAFkizEr6KLTmL8ew7GP59Dv5uCfmN+lQlDf/E+NA1A9b+xlqMUvkQFNMc0cRqEtsN4JRG9baO3Q2qQJFkIt+nNP2I8+yj6u5WoISNRv7vNsSHPfxdx/kIAOjsLve5b1MDf+syQUuE9KjDIkTBat8F4ZZozYWit0blHMTJWYLw2l/JnHsKe8Gf0cbtb76v37qT8hUnonVs9GX69IG0Dolq6qNCx4c43/wdtwjCNexrVsbMjQRiG4wnCzwy3/9HZia3/7yPwMzn2XxCiFqjmLTBNnIYx6xmMV6ahrroOvXubY+VdcKy42+kKynZuRc9MwDRxOspa9bpVesdmjLnT4fQpjHnTMT35PKpdh1qqTd1Ta8liw4YNLFmyBMMwiIuLY9iwYS7nc3NzmTdvHoWFhRiGwV133UVUVBSbNm3iP//5D2VlZZjNZu699166d68768w0dHrnVozk2XDMjvrdH1C33OlcL0gpBX+4H8rL0WkfORaeu+0BOHkCnZGGihmEamnxcg2EL1FBLTE9Ph1j7nT0js2ozt3gN8Mdo7TadkCZTATlZnHs7xMd8z3+Or3SxSj15h8wFiQ51sG6/1GMBUkYL091rInlowsj1kqyMAyD5ORkJk+ejNVqJSEhgejoaNq3/2UVz/fee48+ffpw4403cvDgQWbMmEFUVBTNmzfnqaeewmKx8PPPP5OYmMiiRYtqI2yfp0tOY/zrBWjcxPE/SXiXCmWUUjBytGO70OUfOhKGuRGUlKBuHFbJuwrhWSooGL9nZle5cm/jrj0w/XU6xpy/YbwwyfGEcc6Kwsbab9DJs6FdR8eikM2DMI3/G8bMBIyXn8P0ZFKVkwG11vDTBmjUqNphxL+WNgwoyAd7DuTbodOVtboPe60ki8zMTEJDQwkJcexCFhsby9q1a12ShVLKuYtTUVERwcGOLTEvv/yXCT5hYWGUlJRQWlpKI5n273F69ReQfwzTE/+oNFGcpZSCO//keMJY9p6jSeqqa1FtwmoxWiFcXWhej7osAtPj/8CYPdnxhDFxGqp9R4yvl6OXzoeIrpgenYJqFuAo3yEc09inMV5+zjGv4y/PVVgRWf+8B+PtZNix2XHNNdej7vgjqqX1V8eu84+ht21w7OuSc8SRII7lOvZzOat1W0xPJVW5re+lVivJwm63Y7X+8gOzWq3s2rXLpcyIESOYPn06n3/+OadPn2bKlCkV3ue7774jPDy80kSRlpZGWloaAElJSdhsthrHazabL+r6+urceuuS0+Qu/xBz9ygssQPdul4/NpkTjRtR/OUnBN8xhsb15Gco/96+xVlvm42yGQs59ux49OzJ+A8eQtH/3qLx1dfR8qkZqCb+rhf2i6MYg/wXn6XR0ldo8ddpKD8/jON2Tr75L06lfYwKDCLwT3/FOHmCwndeg20bCLj7IZr+ZhjKr+o1xvTp05Rs20jJhu8p2fg95fsyAUfHfaP2l2Hq0h2/ViH42ULxaxWCLislf87fMc1LJHjaK5jOJDW36l1DtbKfxZo1a9iwYQMPPeRYRG716tXs2rWLMWPGOMt88sknaK255ZZb2LlzJwsWLGD27NmYzqxQeeDAAV544QWeeeYZQkMr3/DmXLKfxa93br2NFZ+g//svR5tu155uv4fWGo7bUcG//q8pb5F/b99SYR+PnCMYsydDXjZExTq23L1Ay4Wx/EP0O/92rKBsDUF/mgolp1GDbkbdfLuziUofPYzxnwWwbSNcHunY3rdDuOP/kbxs9N6dsGcneu8O2L8bykodT+Vndl1UV/aCsPAqV+nVm39w7BnS6UrHpl7V7P1SL/azsFgs5OXlOY/z8vKwWFw7PlesWMHTTz8NQGRkJKWlpRQUFNCiRQvy8vKYNWsW48aNcytRiIujS0sdzUmdrwQ3tvU8l1IK6lGiEEK1CsX01PPoLT+iYuMu+AQAYLpxGMbxPMeIP4Ae0ZhGjkaFuu6kqELaYprwd/R3q9BvJ2MkToTO3Rz7pRfkOwqZG8FlEaiBQ1BXXgWR3Ss+0VQVd49o1KjH0MkvOnZq/LP7KyTXRK0ki4iICLKyssjOzsZisZCRkcH48eNdythsNrZs2cLAgQM5ePAgpaWlBAUFUVhYSFJSEnfddRddu3at4g7iUtLp/+dYJfaBx2Q9J+ETVLAV1c/9yaPqtgegpRXVtgOqe9ULZCqlUDED0T2i0R+8js7c5ih/eRdUeCS063hRqxuYYgZinDyBTn3VsQLwveM89v9srSQLPz8/Ro8eTWJiIoZhMGjQIMLCwkhNTSUiIoLo6Gjuu+8+Fi1axKeffgrA2LFjUUrx+eefc+TIEd59913effddACZPnkyLFjVbV0ZcmOOp4l2I6Ar1dMc3ITxNmUy/arSfCghE3TPWI7GY4odiFJxAf/Y2BAZVuYPhxZI9uCvRkNtydXYW2EIqbQe12Wxkv/8Geul8TI9NveBfTA1JQ/73vhCpd8OhtUa/sQC9+nPUyDGYbri1QpmL7bOQ5T58hDYMjPdew3jmzxgv/Q1tr/hLo0tL0Z+9C5dHQrervRClEKImlFKou/8M18Sit6xDG+WX/B6y3IcP0GWl6JR/or9bBT2iYcdmjOceRd0zFtM5S4cXr/oc8rIx3f2Q9FUIUc84loz/q/P7S02SRQOniwoxFsyA7ZtQv78X9bvbIDsLI/lF9L9mYmxai7rzz9C4CYXvvgaXdYLusuuYEPWRJ/col2TRgGl7LsY/n4MjB1GjJ2DqM8hxIqStY6jgp2+jP01F79yKujoG4+hhTI9MlqcKIUQF0mfRQOlD+zGSnnQ0K43/2y+J4gzl54dp6J2OncbMZvSXH2MOj4Sevb0UsRCiLpMniwZI79iMMe8fjgUAn5iB6hBeZVkV3gXTlDnotI8I6n8D+fJUIYSohCSLBsb4bhV6ycvQuo1jCQBr62qvUf5NUTffQSObDRrYkEIhxKUhyaKB0Fqjl72L/mApRHbHNPbpKpdRFkKIX0uSRQOgy8vRby5Er/4CdW1/1KjHPDoqQgjheyRZ1HO6+BTGv2bC5h9Qv7sNNeyeKlepFEKImpJkUY/p43mOPYIP7HVMsBvwW2+HJIRooCRZ1EO6rBS94hP0J6lgGJgeeQYlQ16FEB4kyaKe0Vt+xEh9FY4cgu7XYLp9TIV19IUQ4lKTZFFP6OzDGG//GzZ+79h799Ep8jQhhKg1kizqOK01+rN30J+8BX6NUH+4HxU3VEY7CSFqlSSLOk5//F/0x2+hrrkedceDqJaW6i8SQohLTJJFHWYse8+RKK6PQ933qAyJFUJ4jXz61FHGl5+g338N1bsf6r5HJFEIIbxKPoHqIOPr5ei3/gW9YlCjJ3hkIxMhhPg1aq0ZasOGDSxZsgTDMIiLi2PYMNfNznNzc5k3bx6FhYUYhsFdd91FVJRjD+gPPviAFStWYDKZeOCBB+jVq1dthV3rjDUr0UvnQfcoTH96AmWWlkIhhPfVyieRYRgkJyczefJkrFYrCQkJREdH0779L/MD3nvvPfr06cONN97IwYMHmTFjBlFRURw8eJCMjAxefPFFjh07xrRp03j55ZcxNbBmGa01+odv0EvmOBYCfDhBRjwJIeqMWkkWmZmZhIaGEhISAkBsbCxr1651SRZKKYqKigAoKioiODgYgLVr1xIbG0ujRo1o3bo1oaGhZGZmEhkZWRuhe5TOy0Fv3wjbNqK3b4Z8O0R0dexW17iJt8MTQggnt5JFSkoKAwcOpGPHjjW6id1ux2q1Oo+tViu7du1yKTNixAimT5/O559/zunTp5kyZYrz2s6dOzvLWSwW7HZ7hXukpaWRlpYGQFJSEjabrUaxApjN5ou6/kKMokJOvvkvStatwcg6AICpRTCNe1xD457R+PeNx9S0mUfuXR1P1rsuk3r7Fql3Da93p5BhGCQmJhIUFES/fv3o16+fy4f/pZCens7AgQO55ZZb2LlzJ3PnzmX27NluXx8fH098fLzzOPciNvGx2WwXdX1VtNYYC2Y4ZmF3i0L1uxF1xVXQ7jLKlKIMKCosgsKiS35vd3iq3nWd1Nu3SL2r1rZt2yrPuZUsRo8ezahRo1i/fj1ff/0177//Pp07d6Z///5cd911+Pv7X/B6i8VCXl6e8zgvLw+LxXVy2YoVK3j66acBiIyMpLS0lIKCggrX2u32CtfWF/qL92H9GtTIMZhuuNXb4QghhNvc7iU2mUxcc801/OUvfyExMZETJ04wf/58HnzwQRYuXFhp09BZERERZGVlkZ2dTVlZGRkZGURHR7uUsdlsbNmyBYCDBw9SWlpKUFAQ0dHRZGRkUFpaSnZ2NllZWXTq1KmG1fUevW0j+v2lqOi+qPih3g5HCCF+Fbc7uIuKilizZg1ff/01+/fv57rrrmPMmDHYbDY++eQT/vGPfzBr1qxKr/Xz82P06NEkJiZiGAaDBg0iLCyM1NRUIiIiiI6O5r777mPRokV8+umnAIwdOxalFGFhYfTp04eJEydiMpkYM2ZMvRsJpe25GItnQWg71P2PoJTydkhCCPGrKK21rq7Q7Nmz2bhxI1dccQUDBgygd+/eNDpnWKdhGIwaNYrXX3/do8H+GocPH67xtZeyTVOXlWLMfBoO/YzpmdmoNnV3OXFpy/UtUm/fUit9Fp07d2bMmDG0bNmy0vMmk4nFixe781Y+R7+dDHt2YHroqTqdKIQQ4kLcas/p2bMnZWVlLq/l5uayb98+53GTJjIv4HzGmpXorz5D3XAr6prrvR2OEELUmFvJYu7cuZSXl7u8VlZWxiuvvOKRoBoCfehn9NJXILIbavj93g5HCCEuilvJIjc31zn7+qzQ0FBycnI8ElR9p7XGeHMBNPbH9KcnZX0nIUS951aysFgs7Nmzx+W1PXv2OJfkEOdZ/y3s3Iq69W5UC/kZCSHqP7f+5L3pppuYOXMmQ4cOJSQkhKNHj/Lxxx8zfPhwT8dX7+jSUox3U6BtB1S/G70djhBCXBJuJYv4+HgCAgJYsWIFeXl5WK1W7rvvPmJiYjwdX72jV3wMOUcw/eU5lJ/sQyGEaBjcbkzv06cPffr08WQs9Z4+cRz96dvQIxrV7WpvhyOEEJeM28ni+PHjZGZmUlBQwLnz+AYPHuyRwOoj/dGbUHIa04jR3g5FCCEuKbeSxffff8/cuXNp06YNBw4cICwsjAMHDtC1a1dJFmfog/vQXy9HDRoik++EEA2OW8kiNTWVsWPH0qdPHx544AFeeOEFvvrqKw4cOODp+OoFrTXG28nQtBnqlju8HY4QQlxybs+zOL+/YsCAAaxevdojQdU7m36AbRtRt9yBCgzydjRCCHHJuZUsgoKCOH78OACtWrVi586dHD16FMMwPBpcfaDLyjDe+bdjRdmBQ7wdjhBCeIRbzVBxcXFs376dmJgYbrrpJp577jmUUtx8882ejq/O06s+h6OHMD0yRWZqCyEaLLc+3YYOHercQ2LAgAF069aN4uJi2reXjly9djVc1gl6RldfWAgh6qlqm6EMw+Dee++ltLTU+ZrNZpNEgWOvCvbvRkV2kw2NhBANWrXJwmQy0bZtWwoKCmojnvrlwF4oK0VFdPV2JEII4VFuNUP17duX559/nt/97ndYrVaXv6K7d+/useDqOr17u+Oby7t4NxAhhPAwt5LF8uXLAXjnnXdcXldK+faeFnt2QLANZbF5OxIhhPAot5LFvHnzLvpGGzZsYMmSJRiGQVxcHMOGDXM5n5KSwtatWwEoKSkhPz+flJQUAN544w3WrVuH1poePXrwwAMP1Ik+Ar1nBypcniqEEA1frYz1NAyD5ORkJk+ejNVqJSEhgejoaJdO8lGjRjm/X7ZsGXv37gVgx44d7Nixg1mzZgEwZcoUfvrpJ7p161YboVdJH7dDXjbE3eLVOIQQoja4lSwefvjhKs8tWLCg2uszMzMJDQ117rYXGxvL2rVrqxxRlZ6ezsiRIwFHU1dJSQllZWVorSkvL6dFixbuhO1Ze3YAyJOFEMInuJUsHn30UZfjY8eO8dlnn3H99de7dRO73Y7VanUeW61Wdu3aVWnZnJwcsrOznR3nkZGRdOvWjT/96U9orfntb39baZJJS0sjLS0NgKSkJGy2mvcjmM3maq8vyPqZInMjbFHXoho1rvG96hJ36t0QSb19i9S7hte7U+jKK6+s8Fq3bt1ITExkyJBLu8RFeno6MTExzkmAR44c4dChQyxcuBCAadOmsW3bNq644gqX6+Lj44mPj3ce5+bm1jgGm81W7fXlW9ZDh3Dy8k/U+D51jTv1boik3r5F6l21tm3bVnnOrbWhKmM2m8nOznarrMViIS8vz3mcl5eHxWKptGxGRobLE8v3339P586d8ff3x9/fn6uvvpqdO3fWNOxLwjEZL1OaoIQQPsPtJcrPdfr0adavX8/VV7u3G1xERARZWVlkZ2djsVjIyMhg/PjxFcodOnSIwsJCIiMjna/ZbDa+/PJLysvL0Vrz008/XfKnmV/t4D4oLYFwmYwnhPANbiWLc58KAJo0acLNN99M//793bqJn58fo0ePJjExEcMwGDRoEGFhYaSmphIREUF0tGNdpfT0dGJjY12GxcbExLBlyxYef/xxAHr16uUs7y1695nO7Qh5shBC+Aalz90jtQE5fPhwja+trm3PWDwLvXMrfjOX1PgedZG05foWqbdvqZU+iw8//JDMzEyX1zIzM/noo4/cubzB0Xt2gPRXCCF8iFvJ4rPPPqswXLV9+/Z89tlnHgmqLtMnjkHuUWmCEkL4FLeSRVlZGebzNvYxm82UlJR4JKg67Wx/hXRuCyF8iFvJIjw8nC+++MLlteXLlxMeHu6RoOoyvXs7+JnhsghvhyKEELXGrdFQ999/P9OnT2f16tWEhIRw9OhRjh8/zpQpUzwdX52j9+6ADuENZta2EEK4w61kERYWxssvv03ATmIAABq3SURBVMyPP/5IXl4e1113Hddccw3+/v6ejq9O0WVlsG8Xqt9vvB2KEELUKreShd1up3Hjxi4zq0+ePIndbq9yJnaDdGgflJSA7IwnhPAxbvVZzJw5E7vd7vKa3W53LhvuK7SsNCuE8FFuJYvDhw/ToUMHl9c6dOjAoUOHPBJUnbV7O7SwgKWVtyMRQoha5VayCAoK4siRIy6vHTlyhObNm3skqLpK79kBEV3qxC59QghRm9zqsxg0aBCzZ8/mjjvuICQkhCNHjpCamsrgwYM9HV+doU8ch5wjqAG/9XYoQghR69xKFsOGDcNsNrN06VLy8vKwWq0MHjyYW27xoS1F98hkPCGE73IrWZhMJoYOHcrQoUOdrxmGwfr164mKivJYcHWJ3rMd/PxkMp4Qwie5lSzOtX//flatWsU333xDeXk5ycnJnoirztG7d0BYOKpxE2+HIoQQtc6tZJGfn8/XX3/N6tWr2b9/P0opHnjgAQYNGuTp+OqO7MOobu5t9iSEEA3NBZPFt99+y6pVq9i4cSPt2rWjb9++PPHEEzzzzDPExMTQuLEPLXlRVAgBvjX6SwghzrpgspgzZw6BgYFMmDCBa6+9trZiqnN0WSmUnIamAd4ORQghvOKCyeLhhx9m1apVvPjii0RERNC3b98K2576hFNFjq/NJFkIIXzTBZPFwIEDGThwIDk5OaxatYrPP/+c119/HYD169fTv39/TCa35vXVb0WFjq+SLIQQPsqtDu5WrVpx2223cdttt7F9+3ZWrVrFa6+9xn//+18WLVrk1o02bNjAkiVLMAyDuLg4hg0b5nI+JSWFrVu3AlBSUkJ+fj4pKSkA5ObmsnDhQvLy8gBISEigdevW7tbx4p1JFqppYO3dUwgh6pBfPXS2a9eudO3aldGjR7N27Vq3rjEMg+TkZCZPnozVaiUhIYHo6GiXrVpHjRrl/H7ZsmXs3bvXefzKK68wfPhwevbsSXFxce03g5066fgqTxZCCB9V4zakRo0aERsb61bZzMxMQkNDCQkJwWw2Exsbe8FEk56eTt++fQE4ePAg5eXl9OzZEwB/f3+aNKnluQ7SDCWE8HG/+smiJux2O1ar1XlstVrZtWtXpWVzcnLIzs6me/fugGPF24CAAGbNmkV2djY9evTg7rvvrtBXkpaWRlpaGgBJSUnYbLYax2s2m12uLzIpCgBLuzD8LuJ967rz6+0rpN6+Repdw+svYSyXRHp6OjExMc5kYBgG27Zt44UXXsBms/HSSy+xcuXKCosYxsfHEx8f7zzOzc2tcQw2m83leiMnGwB78WnURbxvXXd+vX2F1Nu3SL2r1rZt2yrPudUMVdVTQGZmpjuXY7FYnJ3TAHl5eVXusJeRkeGyI5/FYqFjx46EhITg5+fHtddey549e9y67yVTVAgmEzTxrW1khRDiLLeSxfTp0yt9PTEx0a2bREREkJWVRXZ2NmVlZWRkZBAdHV2h3KFDhygsLCQyMtL5WqdOnSgqKuLEiRMAbNmyxaVjvFacOgnNAnxvfokQQpxxwWYowzAA0Fo7/zvr6NGj+Pn5uXUTPz8/Ro8eTWJiIoZhMGjQIMLCwkhNTSUiIsKZONLT0ytM+jOZTNx77738/e9/R2tNeHi4S3NTrSgqlNnbQgifdsFkceeddzq/v+OOO1zOmUwmfv/737t9o6ioqArLmd9+++0uxyNHjqz02p49e3p1v29dVAjNZI6FEMJ3XTBZvPLKK2itmTp1Ks899xxaa5RSKKUICgrynYUETxXKsFkhhE+7YLJo1aoVAPPnzwcczVL5+fkEBwd7PrK6pKgQQn2szkIIcQ63hs4WFhby6quvsmbNGuf2qj/88AOZmZkVmqcapKJCVNNm3o5CCCG8xq3RUIsXL6ZZs2bMnz8fs9mRXyIjI8nIyPBocHWGNEMJIXycW08WmzdvZtGiRc5EARAUFER+fr7HAqsrdFkZnC6WZCGE8GluPVk0a9aMgoICl9dyc3N9o+/i7F4WsuKsEMKHuZUs4uLimD17Nlu2bEFrzc6dO5k3bx433HCDp+PzPllxVggh3GuGuvXWW2ncuDHJycmUl5ezYMEC4uPjGTJkiKfj876ze1lIshBC+DC3koVSiiFDhvhGcjjf2eXJZQa3EMKHXTBZ5OTkYDKZnMuLnz59mvfff58DBw4QGRnJ0KFDG/62qqdkLwshhLjgJ/3ChQvZvXu38zg5OZmMjAzatGnDV199xVtvveXxAL1Ny8ZHQghx4WSxf/9+5w51xcXFZGRkMGHCBO69916efPJJ35hnIclCCCEunCzKysrw93fs4bB7926aNm1KeHg4AO3ataswnLZBKioEZYImTb0diRBCeM0Fk0Xr1q3ZunUrAD/88APdunVznjtx4oRvLCQoe1kIIcSFO7hHjBjBzJkzCQkJ4dChQ0ydOtV5bu3atXTq1MnT8XnfqSJpghJC+LwLJovevXuTlJTEvn37CA8Pp3Xr1s5z7dq1o0uXLh4P0Nu0bHwkhBDVz+AODQ3lp59+ckkUAF27diUtLc1jgdUZRbKIoBBCuDVJYtWqVZW+vnr16ksaTJ10qhBkeXIhhI+7YDPUihUrACgvL3d+f1Z2djbNmzf3XGR1RVGhLPUhhPB5F0wWX3/9NeAYQnv2+7NatGjBuHHj3L7Rhg0bWLJkCYZhEBcXx7Bhw1zOp6SkOEdelZSUkJ+fT0pKivN8UVEREydOpHfv3owZM8bt+160okJZcVYI4fMumCyeffZZAN56662L2hHPMAySk5OZPHkyVquVhIQEoqOjad++vbPMqFGjnN8vW7aMvXv3urxHamoqV1xxRY1jqAldXg6nT0mfhRDC57nVZzFkyBCKi4sBxwf/V199xapVqzAMw62bZGZmEhoaSkhICGazmdjYWNauXVtl+fT0dPr27es83rNnD/n5+Vx11VVu3e+SkXWhhBACcHPV2aSkJB588EEuv/xy3nzzTdatW4efnx979+51eSKoit1udy5GCGC1Wtm1a1elZXNycsjOzqZ79+6AIzm9/vrrPProo2zevLnKe6SlpTlHZyUlJWGz2dypWqXMZjM2m42y0mLygOatQ2l6Ee9XX5ytt6+RevsWqXcNr3enUFZWFh07dgTgm2++Yfr06fj7+zNx4kS3ksWvkZ6eTkxMjHM12+XLl3P11Ve7JJvKxMfHEx8f7zzOzc2tcQw2m43c3Fz04YMAnCw3KLyI96svztbb10i9fYvUu2pt27at8pxbycJkMlFWVkZWVhbNmjXDZrNhGIazaao6FouFvLw853FeXh4Wi6XSshkZGS4d2Dt37mTbtm0sX76c4uJi53pVd999t1v3viiyiKAQQgBuJotevXrx0ksvUVBQQGxsLAAHDx6s8gP/fBEREWRlZZGdnY3FYiEjI4Px48dXKHfo0CEKCwuJjIx0vnZuuZUrV7J79+7aSRQgyUIIIc5wK1k89NBDrFq1Cj8/P/r37w9AQUEBI0aMcOsmfn5+jB49msTERAzDYNCgQYSFhZGamkpERATR0dGAowkqNja2zizap4vO7L8tQ2eFED5Oaa21u4UNwyA/P5/g4GBPxnRJHD58uMbXnm3bM5Z/gH5nCaZ/voXygVnc0pbrW6TevqVW+iwKCwt59dVXWbNmDWazmaVLl/LDDz+QmZl5UfMv6jznXhb+3o5ECCG8yq15FosXL6ZZs2bMnz8fs9mRXyIjIxv+TnlFjnWhVEPfZ1wIIarh1pPF5s2bWbRokTNRAAQFBZGfn++xwOqEU7LirBBCgJtPFs2aNauwhWpubm696Lu4GFqWJxdCCKCaZPHNN98AEBcXx+zZs9myZQtaa3bu3Mm8efO44YYbaiVIr5GNj4QQAqgmWSxevBiAW2+9ldjYWJKTkykvL2fBggVER0czZMiQWgnSa05JshBCCKimz+LsqFqlFEOGDGn4yeF8p2QvCyGEgGqShWEYbNmy5YJvcHbBvwZJ+iyEEAKoJlmUlpaycOFCqpq3p5TilVde8Uhg3qbLy6H4lDRDCSEE1SQLf3//BpsMqlVc5PgqTxZCCOHe0FmfJIsICiGE0wWTxa9YNqrhOZMspINbCCGqSRavv/56bcVR98iKs0II4STNUFWR/beFEMJJkkUVtPRZCCGEkySLqpxNFjJ0VgghJFlU6VQhKAX+Tb0diRBCeJ0ki6rIXhZCCOEkn4RVkRVnhRDCya3Njy6FDRs2sGTJEgzDIC4ujmHDhrmcT0lJYevWrQCUlJSQn59PSkoK+/btY/HixZw6dQqTycTw4cOJjY31eLxaNj4SQginWkkWhmGQnJzM5MmTsVqtJCQkEB0dTfv27Z1lRo0a5fx+2bJl7N27F4DGjRvzyCOP0KZNG+x2O5MmTeKqq64iIMDDH+RFJ6GZzLEQQgiopWaozMxMQkNDCQkJwWw2Exsby9q1a6ssn56eTt++fQFo27Ytbdq0AcBisdCiRQtOnDjh+aDP9FkIIYSopScLu92O1Wp1HlutVnbt2lVp2ZycHLKzsytd+jwzM5OysjJCQkIqnEtLSyMtLQ2ApKQkbDZbjeM1m82YThfTONhKi4t4n/rGbDZf1M+tvpJ6+xapdw2vv4SxXBLp6enExMRgOm8U0rFjx5g7dy7jxo2rcA4gPj6e+Ph453Fubm6NY7DZbBgnT3Da5HdR71Pf2Gw2n6rvWVJv3yL1rlrbtm2rPFcrzVAWi4W8vDzncV5eHhaLpdKyGRkZXH/99S6vFRUVkZSUxJ133klkZKRHY4Vz9rKQDm4hhABqKVlERESQlZVFdnY2ZWVlZGRkEB0dXaHcoUOHKCwsdEkIZWVlzJo1i/79+xMTE1Mb4TpGQoEkCyGEOKNWmqH8/PwYPXo0iYmJGIbBoEGDCAsLIzU1lYiICGfiSE9PJzY2FqWU89qMjAy2bdtGQUEBK1euBGDcuHF07NjRY/HqQllxVgghzlVrfRZRUVFERUW5vHb77be7HI8cObLCdf3796d///4eje18RmEBIHtZCCHEWTKDuxLOJwtJFkIIAUiyqJThbIaSZCGEECDJolL6TDOUPFkIIYSDJItKGNIMJYQQLiRZVEIXnjyzl4Us9yGEECDJolJGYQH4y14WQghxlnwaVkIXnpQmKCGEOIcki0rowgIZCSWEEOeQZFEJQ54shBDChSSLSuiik7KXhRBCnEOSRSWMwgJZ6kMIIc4hyaISjg5uWURQCCHOkmRxHm2Uo4sKpYNbCCHOIcnifKdOOb5KM5QQQjhJsjhfkSz1IYQQ55Nkcb5TRQAoaYYSQggnSRbnky1VhRCiAkkW5yuSZCGEEOeTZHEefTZZSDOUEEI41doe3Bs2bGDJkiUYhkFcXBzDhg1zOZ+SksLWrVsBKCkpIT8/n5SUFABWrlzJ+++/D8Dw4cMZOHCg5wI9dbaDW+ZZCCHEWbWSLAzDIDk5mcmTJ2O1WklISCA6Opr27ds7y4waNcr5/bJly9i7dy8AJ0+e5N133yUpKQmASZMmER0dTWCghz7MnU8WTT3z/kIIUQ/VSjNUZmYmoaGhhISEYDabiY2NZe3atVWWT09Pp2/fvoDjiaRnz54EBgYSGBhIz5492bBhg+eCLSpENQtAmfw8dw8hhKhnauXJwm63Y7VancdWq5Vdu3ZVWjYnJ4fs7Gy6d+9e6bUWiwW73V7hurS0NNLS0gBISkrCZrPVKNZ8o5zSgOY1vr4+M5vNUm8fIvX2LRdb71rrs3BXeno6MTExmH7lLnXx8fHEx8c7j3Nzc2t0//JjeZgDAmt8fX1ms9mk3j5E6u1b3Kl327ZtqzxXK81QFouFvLw853FeXh4Wi6XSshkZGVx//fVVXmu326u89pI40wwlhBDiF7WSLCIiIsjKyiI7O5uysjIyMjKIjo6uUO7QoUMUFhYSGRnpfK1Xr15s3LiRkydPcvLkSTZu3EivXr08F2xRISqguefeXwgh6qFaaYby8/Nj9OjRJCYmYhgGgwYNIiwsjNTUVCIiIpyJIz09ndjYWJRSzmsDAwP5wx/+QEJCAgC33Xab50ZCAZwqxBQQSLnn7iCEEPVOrfVZREVFERUV5fLa7bff7nI8cuTISq8dPHgwgwcP9lhsLooKUQEyx0IIIc4lM7jPoQ0DioswNZNmKCGEOJcki3MVF4HW8mQhhBDnkWRxLq1Rvfth7nC5tyMRQog6pc7Ns/AmFdAc9acnaGKzUeCD47CFEKIq8mQhhBCiWpIshBBCVEuShRBCiGpJshBCCFEtSRZCCCGqJclCCCFEtSRZCCGEqJYkCyGEENVSWmvt7SCEEELUbfJkUYlJkyZ5OwSvkHr7Fqm3b7nYekuyEEIIUS1JFkIIIarlN3Xq1KneDqIuCg8P93YIXiH19i1Sb99yMfWWDm4hhBDVkmYoIYQQ1ZJkIYQQolqy+dE5NmzYwJIlSzAMg7i4OIYNG+btkDxm/vz5rFu3jhYtWjB79mwATp48yUsvvUROTg6tWrViwoQJBAY2nC1mc3NzmTdvHsePH0cpRXx8PEOGDGnw9S4pKeHZZ5+lrKyM8vJyYmJiGDlyJNnZ2cyZM4eCggLCw8N59NFHMZsb3keCYRhMmjQJi8XCpEmTfKbe48aNw9/fH5PJhJ+fH0lJSRf3u66F1lrr8vJy/cgjj+gjR47o0tJS/fjjj+sDBw54OyyP2bp1q969e7eeOHGi87WlS5fqDz74QGut9QcffKCXLl3qrfA8wm636927d2uttS4qKtLjx4/XBw4caPD1NgxDnzp1SmutdWlpqU5ISNA7duzQs2fP1t98843WWutFixbpL774wptheszHH3+s58yZo2fMmKG11j5T77Fjx+r8/HyX1y7md12aoc7IzMwkNDSUkJAQzGYzsbGxrF271tthecyVV15Z4S+KtWvXMmDAAAAGDBjQ4OofHBzsHA3StGlT2rVrh91ub/D1Vkrh7+8PQHl5OeXl5Sil2Lp1KzExMQAMHDiwwdUbIC8vj3Xr1hEXFweA1ton6l2Vi/ldb3jPXjVkt9uxWq3OY6vVyq5du7wYUe3Lz88nODgYgJYtW5Kfn+/liDwnOzubvXv30qlTJ5+ot2EYPPXUUxw5coTf/OY3hISE0KxZM/z8/ACwWCzY7XYvR3nppaSkcM8993Dq1CkACgoKfKLeZyUmJgJwww03EB8ff1G/65IsRKWUUiilvB2GRxQXFzN79mxGjRpFs2bNXM411HqbTCZmzpxJYWEhs2bN4vDhw94OyeN+/PFHWrRoQXh4OFu3bvV2OLVu2rRpWCwW8vPzmT59Om3btnU5/2t/1yVZnGGxWMjLy3Me5+XlYbFYvBhR7WvRogXHjh0jODiYY8eOERQU5O2QLrmysjJmz55Nv379uO666wDfqPdZAQEBdOvWjZ07d1JUVER5eTl+fn7Y7fYG9/u+Y8cOfvjhB9avX09JSQmnTp0iJSWlwdf7rLP1atGiBb179yYzM/Oiftelz+KMiIgIsrKyyM7OpqysjIyMDKKjo70dVq2Kjo5m1apVAKxatYrevXt7OaJLS2vNwoULadeuHTfffLPz9YZe7xMnTlBYWAg4RkZt2rSJdu3a0a1bN9asWQPAypUrG9zv+1133cXChQuZN28ef/nLX+jevTvjx49v8PUGx9Pz2aa34uJiNm3aRIcOHS7qd11mcJ9j3bp1vPbaaxiGwaBBgxg+fLi3Q/KYOXPm8NNPP1FQUECLFi0YOXIkvXv35qWXXiI3N7dBDiHdvn07f/vb3+jQoYPz8fvOO++kc+fODbre+/fvZ968eRiGgdaaPn36cNttt3H06FHmzJnDyZMnufzyy3n00Udp1KiRt8P1iK1bt/Lxxx8zadIkn6j30aNHmTVrFuAY1NC3b1+GDx9OQUFBjX/XJVkIIYSoljRDCSGEqJYkCyGEENWSZCGEEKJakiyEEEJUS5KFEEKIakmyEKKOGTlyJEeOHPF2GEK4kBncQlRj3LhxHD9+HJPpl7+tBg4cyJgxY7wYlRC1S5KFEG546qmn6Nmzp7fDEMJrJFkIUUMrV67kyy+/pGPHjqxevZrg4GDGjBlDjx49AMdKxosXL2b79u0EBgZy6623Eh8fDzhWgf3www/56quvyM/Pp02bNjzxxBPYbDYANm3axD/+8Q9OnDhB3759GTNmDEopjhw5woIFC9i3bx9ms5nu3bszYcIEr/0MhO+QZCHERdi1axfXXXcdycnJfP/998yaNYt58+YRGBjIyy+/TFhYGIsWLeLw4cNMmzaN0NBQunfvzieffEJ6ejoJCQm0adOG/fv306RJE+f7rlu3jhkzZnDq1CmeeuopoqOj6dWrF2+99RZXXXWVc+e7PXv2eLH2wpdIshDCDTNnznTugQBwzz33YDabadGiBTfddBNKKWJjY/n4449Zt24dV155Jdu3b2fSpEk0btyYjh07EhcXx6pVq+jevTtffvkl99xzj3PZ6I4dO7rcb9iwYQQEBDhXid23bx+9evXCbDaTk5PDsWPHsFqtdO3atTZ/DMKHSbIQwg1PPPFEhT6LlStXYrFYXPYEaNWqFXa7nWPHjhEYGEjTpk2d52w2G7t37wYcS+CHhIRUeb+WLVs6v2/SpAnFxcWAI0m99dZbPP300wQEBHDzzTczePDgS1JHIS5EkoUQF8Fut6O1diaM3NxcoqOjCQ4O5uTJk5w6dcqZMHJzc517DFitVo4ePUqHDh1+1f1atmzJQw89BDhW0Z02bRpXXnkloaGhl7BWQlQk8yyEuAj5+fksW7aMsrIyvv32Ww4dOsTVV1+NzWajS5cuvPnmm5SUlLB//36++uor+vXrB0BcXBypqalkZWWhtWb//v0UFBRUe79vv/3WuUlXQEAAQIPc2U/UPfJkIYQbnn/+eZd5Fj179qR379507tyZrKwsxowZQ8uWLZk4cSLNmzcH4LHHHmPx4sX8+c9/JjAwkBEjRjibsm6++WZKS0uZPn06BQUFtGvXjscff7zaOHbv3u3c7a1ly5Y88MADF2zOEuJSkf0shKihs0Nnp02b5u1QhPA4aYYSQghRLUkWQgghqiXNUEIIIaolTxZCCCGqJclCCCFEtSRZCCGEqJYkCyGEENWSZCGEEKJa/w9vQy+htaubGgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQmUGqYnFY9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}